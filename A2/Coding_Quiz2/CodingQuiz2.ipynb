{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "described-israel",
   "metadata": {},
   "source": [
    "## Instructions:\n",
    "- You can use NN libraries such as tensorflow, pytorch, etc. But implement GAN and VAE on your own.\n",
    "- Zero tolerance for plagiarism. Do not copy from Practice and Share; the student who submitted there originally only can use; Github tracks who pushed what code.\n",
    "- Total marks: 50\n",
    "- Marks will be for answering the questions asked below, not for the codes. Use plots, tables, etc. to convey your answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-raleigh",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(5)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considered-float",
   "metadata": {},
   "source": [
    "# VAEs vs GANs\n",
    "The objective of this exercise is to compare VAEs and GANs for a generative modeling task (generating samples from a mixture of Gaussians).\n",
    "\n",
    "- Prepare the target probability distribution $p_x^*$ as a GMM with 5 components.\n",
    "(Using snippets from CodingQuiz1.py is allowed)\n",
    "- Construct and train a VAE to model $p^*_x$.\n",
    "- Construct and train a GAN to model $p^*_x$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "future-multimedia",
   "metadata": {},
   "source": [
    "## Questions\n",
    "1. Plot the samples from original $p^*_x$, VAE and GANs to compare them visually. (You may plot them on same or different plots) [10 marks]\n",
    "2. Quantify the performance of the two models and compare them. (Think what all metrics can you use - report as many as you can) [10 marks]\n",
    "3. Expressivity vs Efficiency: Which of the two models is more expressive? Which is more efficient? (Number of parameters vs performance, computations vs performance, etc.) [10 marks]\n",
    "4. Compare the pros and cons of the two models in a table. [10 marks]\n",
    "5. Do you find a structure in the latent space in the two models? E.g., each Gaussian component of $p^*_x$ may correspond to a specific region in the latent space. [10 marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hawaiian-friday",
   "metadata": {},
   "source": [
    "## Codes and Answers\n",
    "It would be appreciated if you write modular codes and re-use them while answering different parts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a05bbb9",
   "metadata": {},
   "source": [
    "## Q1 and Q5\n",
    "For the plots please check the GAN.ipynb and VAE.ipynb notebook.  \n",
    "\n",
    "#### GAN\n",
    "After the training, we plot the original data with each component of the GMM coloured with a different colour. We then sample noise from the standard normal distribution and transform it using our GAN.   \n",
    "$x = G(z)$  \n",
    "For each $x$ we see which component of the GMM it is most likely to be from. We colour the $G(z)$ and $z$ accordingly.   \n",
    "\n",
    "There is also a gan.mp4 which shows us the evolution of the model as it generates data from the same noise vector after each epoch.  \n",
    "\n",
    "#### VAE\n",
    "After training our VAE, we plot the complete reconstructed data.    \n",
    "\n",
    "In order to visual the spaces better, we sample from each component of the GMM and plot the reconstructed samples of that particular component using the same colour. This gives a better sense of the reconstruction. For each component we also plot the encoded data $z = E(x)$ using the same colour. This helps us visualize the structure in the latent space.    \n",
    "\n",
    "We can see that each component has a separate cluster in the latent space. \n",
    "\n",
    "There is a vae.mp4 which shows us the evolution of the model as it learns to encode and decode the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d392d9d",
   "metadata": {},
   "source": [
    "## Q2 \n",
    "1. Log Likelihood \n",
    "2. Average Minimum distance from any training sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4888752c",
   "metadata": {},
   "source": [
    "## Q3 \n",
    "### Expressivity\n",
    "This is a more qualititative assessment. In this sense, GANs seem to be more expressive because it learns to transform a latent space into samples from $p^*(x)$.  From the video and the spread of $x = G(z)$, we can see that GANs are more expressive and can capture the shape of the training data better than VAEs.  \n",
    "\n",
    "On the other hand, the VAE learns to reconstruct the samples from $p^*(x)$. While the sampling part in the VAE helps to bring in some more diversity from the latent space, the main purpose is to bring more structure to the latent space.  \n",
    "\n",
    "Another way of thinking about expressivity is that a GAN is learning to be creative and original (with respect to some standard) and generates data which is as good as real. This is done from noise.  \n",
    "On the other hand, VAE has some kind of supervision since it is learning to reconstruct the data. It is possible that interpolating in the latent space can give us some new kind of data but compared too GAN, VAE is still restricted in terms of training.\n",
    "\n",
    "#### Another thought on VAE \n",
    "VAEs learn a latent space to represent the real data. By interpolating between different points in the latent space we could get data which is a never-seen-before mix of the original data. This might be one viewpoint on the expressivity on VAEs, however, for the experiments conducted, GANs seem to be more expressive and modelling the data better.\n",
    "\n",
    "### Efficiency\n",
    "The 2 models give different types of results. However, we can still have metric like \"Number of Parameters vs performance\" and \"Training time vs performance\".\n",
    "\n",
    "##### Number of Parameters\n",
    "##### GAN : \n",
    "4482 (G) + 17537 (D)\n",
    "##### VAE :\n",
    "18054\n",
    "\n",
    "GANs have more parameters required for the overall training loop.  \n",
    "\n",
    "##### Training Time \n",
    "GAN training : 732.8 s for 250 epochs => 2.9312 s / epoch (batch size = 256, training data = 100000)  \n",
    "VAE training : 682.2 s for 250 epochs => 2.7288 s / epoch (batch size = 128, training data = 100000)   \n",
    "GANs take significantly longer to train (consider batch size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ab3112",
   "metadata": {},
   "source": [
    "## Q4 \n",
    "#### GAN\n",
    "| Pros                          | Cons                                  |\n",
    "| -----------                   | -----------                           |\n",
    "| More expressive               | Unstable and Tricky Training          |\n",
    "| Realistic data generation     | Long Training Time                    |\n",
    "| -                             | Cannot model $p(z \\| x) $             | \n",
    "| -                             | Requires a lot of data                | \n",
    "\n",
    "#### VAE\n",
    "| Pros                                                              | Cons                                                                          |\n",
    "| -----------                                                       | -----------                                                                   |\n",
    "| Standard way to compare 2 VAEs using log likelihood               | Generated data is blurred because of the sampling and reconstrcution          |\n",
    "| Can estimate latent variables, i.e $p(z \\| x)$                    | Long Training Time                                                            |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
